
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time


class UrunListesiAlma:
    def __init__(self, base_url, max_pages=10):
        self.base_url = base_url
        self.max_pages = max_pages
        self.all_products = []
        self.total_reviews = 0
        # **ğŸ“Œ Selenium TarayÄ±cÄ±yÄ± BaÅŸlat**
        options = Options()
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    def accept_cookies(self):
        """Ã‡erezleri kabul eder (varsa)."""
        try:
            cookie_button = self.driver.find_element(By.ID, "onetrust-accept-btn-handler")
            cookie_button.click()
            print("âœ… Ã‡erezler kabul edildi!")
            time.sleep(2)
        except:
            print("âš ï¸ Ã‡erez butonu bulunamadÄ±, devam ediliyor...")

    def get_products(self):
        """ÃœrÃ¼nleri Ã§eker ve listeye ekler."""
        try:
            product_titles = self.driver.find_elements(By.XPATH, "//h3[@data-test-id='product-card-name']")

            for title in product_titles:
                product_name = title.text.strip()  # ÃœrÃ¼n adÄ±nÄ± al

                try:
                    # **ğŸ“Œ ÃœrÃ¼n Linkini Bulma**
                    product_link = title.find_element(By.XPATH, "./ancestor::a").get_attribute("href")
                except:
                    product_link = "Link BulunamadÄ±"

                try:
                    # **ğŸ“Œ Yorum SayÄ±sÄ±nÄ± Bulma**
                    review_element = title.find_element(By.XPATH, "./following::div[@data-test-id='review']")
                    review_count = review_element.text.strip()
                except:
                    review_count = "0"  # EÄŸer yorum bulunamazsa 0 ata

                # **ğŸ“Œ Yorum SayÄ±sÄ±nÄ± SayÄ±ya Ã‡evir ve ToplamÄ± GÃ¼ncelle**
                try:
                    reviews_clean = int(review_count.replace(".", "").replace(",", ""))  # 1.512 â†’ 1512, 1,512 â†’ 1512
                    self.total_reviews += reviews_clean
                except ValueError:
                    print(f"âš ï¸ HatalÄ± yorum sayÄ±sÄ± algÄ±landÄ± ve atlandÄ±: {review_count}")
                    reviews_clean = 0

                self.all_products.append([product_name, reviews_clean, product_link])
        except:
            print("âš ï¸ ÃœrÃ¼n baÅŸlÄ±klarÄ± bulunamadÄ±!")

    def scrape(self, page_limit=None):
        """
        Hepsiburada'dan Ã¼rÃ¼nleri Ã§eker ve Pandas DataFrame olarak dÃ¶ndÃ¼rÃ¼r.
        - page_limit: KaÃ§ sayfanÄ±n verisini almak istiyorsan belirtebilirsin.
                      VarsayÄ±lan olarak None, yani `self.max_pages` kadar Ã§eker.
        """
        if page_limit is None:
            page_limit = self.max_pages  # EÄŸer belirtilmezse, varsayÄ±lan `max_pages` deÄŸeri kullanÄ±lÄ±r

        for page_num in range(1, page_limit + 1):
            url = f"{self.base_url}&sayfa={page_num}"
            print(f"\nğŸŒ Sayfa {page_num} YÃ¼kleniyor: {url}")

            # SayfayÄ± aÃ§
            self.driver.get(url)
            time.sleep(5)  # **SayfanÄ±n yÃ¼klenmesini bekle**

            # **Ã‡erezleri kabul et (ilk sayfada)**
            if page_num == 1:
                self.accept_cookies()

            # **ÃœrÃ¼nleri Ã§ek**
            self.get_products()

        # **ğŸ“Œ TarayÄ±cÄ±yÄ± kapat**
        self.driver.quit()

        # **ğŸ“Œ SonuÃ§larÄ± Pandas DataFrame'e Ã‡evir**
        df = pd.DataFrame(self.all_products, columns=["Product_Name", "Comment_Count", "Link"])

        # **ğŸ“Œ Toplam Yorum ve ÃœrÃ¼n SayÄ±sÄ±nÄ± YazdÄ±r**
        print(f"\nğŸ”¢ Toplam Yorum SayÄ±sÄ±: {self.total_reviews}")
        print(f"ğŸ“¦ Toplam ÃœrÃ¼n SayÄ±sÄ±: {len(self.all_products)}")

        # **ğŸ“Œ DataFrame'i Return Et**
        return df


# **ğŸ“Œ KullanÄ±m**
if __name__ == "__main__":
    base_url = input("LÃ¼tfen Hepsiburada Ã¼rÃ¼n listesinin URL'sini girin: ").strip()
    scraper = UrunListesiAlma(base_url)

    # KullanÄ±cÄ± kaÃ§ sayfa Ã§ekeceÄŸini belirleyebilir
    page_limit = 2  # int(input("KaÃ§ sayfa verisini almak istiyorsunuz? (VarsayÄ±lan: 5) ") or 5)

    product_df = scraper.scrape(page_limit=page_limit)

    # **ğŸ“Œ SonuÃ§larÄ± Tabloda YazdÄ±r**
    print("\nâœ… ÃœrÃ¼nler Tablosu:")
    print(product_df.to_string(index=False))  # Daha dÃ¼zenli yazdÄ±rma
